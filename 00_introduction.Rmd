---
output: html_document
---

# Introduction {-}

The supply of socio-economic data available to researchers has increased considerably over the past decade. The demand for data, and the tools and methods available to exploit these data in more diverse and efficient manners, have also seen major advances. This brings unprecedented opportunities to increase the use and value of existing data. "Data that were initially collected with one intention can be reused for a completely different purpose. (…) Because the potential of data to serve a productive use is essentially limitless, enabling the reuse and repurposing of data is critical if data are to lead to better lives.” ([World Bank, World Development Report 2021](https://www.worldbank.org/en/publication/wdr2021)) 

But data can be challenging to find, access, and use. Analysts often spend an significant time locating and wrangling data. Many researchers rely on tribal knowledge to identify datasets of interest, leaving many valuable datasets underutilized. These market failures must be addressed. Data libraries and repositories play a crucial role in this endeavour. By curating data and maintaining online data catalogs, they contribute to making data more discoverable, visible, and usable. But many still rely on sub-optimal technological technological solutions. Keyword-based search engines, limited metadata, and the absence of search engine optimization, result in limited findability and visibility of their assets. Open source tools to implement advanced search features including semantic searchability, and to transform data catalogs into visible and interoperable recommender systems that would better serve the needs of data users. The most successful e-commerce platforms provide a good model of what a market place for data could be: a system that provides users with hassle-free ways of identifying and acquiring -preferably at no cost in the case of research data- the products that best fit their purposes and preferences, and that provides data producers with a trustable platform to publish their assets in a safe and responsible manner.

To effectively achieve such an objective, the availability of comprehensive and structured metadata are essential. Metadata are an essential component of data credibility, discoverability, visibility, and usability. Adopting metadata standards and schemas[^1] is a practical and efficient solution to promote the completeness and quality of metadata, as well as the inter-operability of data catalogs that utilize them. Metadata are These standards and schemas must be tailored to the type of data being documented. This Guide offers a set of recommended standards and schemas and provides guidance and justification for their implementation.

Chapter 1 of this guide outlines the challenges associated with finding and using data. Chapter 2 describes the essential features of a modern data catalog, and Chapter 3 explains how rich and structured metadata can enable advanced search algorithms and recommender systems optimized for data discoverability. Finally, Chapters 4 to 13 present specific standards and schemas we recommend for various data types, along with examples of their use.

In this document, we take a broad approach to defining data, with a focus on data types commonly used in social sciences. The metadata schemas we present cover multiple types of data, both structured and unstructured. It is important to distinguish between different data types as this helps us identify the most appropriate metadata standards and tools for documenting them. The following are the data types we cover in this guide:

- Structured (quantitative) data:
   - **Microdata**: This refers to unit-level data on a population of individuals, households, dwellings, facilities, establishments, transactions, or other similar units. Microdata can be generated from surveys, censuses, administrative recording systems, or sensors.
   - **Statistical tables**: This type of data provides aggregated statistical information in the form of cross-tables. Examples include data published in statistics yearbooks or census reports. Statistical tables are often derived from microdata and may include counts, means, percentages, or any other types of data summary.
   - **Indicators and time series**: This type of data consists of summary measures derived from observed facts, often from microdata. When repeated over time at a regular frequency, indicators form a time series.
   - **Geographic datasets and data services**: Geographic (or geospatial) data identify and depict geographic locations, boundaries, and characteristics of the surface of the earth. They can be provided in the form of datasets (raster or vector data) or data services (web applications).

- Unstructured data:
   - **Text**: This type of data comprises collections of documents, such as books, papers, reports, manuals, and other textual resources. These form a corpus. Natural language processing (NLP) techniques can be used to convert a corpus into structured information. Textual information extracted from social media (such as tweets or news) can also be submitted to NLP models to generate quantitative (structured) datasets, e.g., by applying classification techniques.
   - **Images**: Digital images can be processed using machine learning algorithms (such as object detection, classification, or others).
   - **Audio and video recordings**: Speech-to-text algorithms can transform audio and video recordings into text files, making them a type of data in the same way we consider text as data.
   - **Programs and scripts**: Although they are not data per se, we treat the programs and scripts used to edit, transform, tabulate, analyze, model, and visualize data as data-related resources that need to be documented, catalogued, and disseminated. Sharing code and scripts contributes to making data and statistics transparent and usable, and increases the credibility of data analysis by assuring reproducibility and replicability.

[^1]: We refer to metadata *standards* when a community or organization is in charge of the development and maintenance of a metadata schema, with formal governance. We use the term metadata *schema* when no formal governance is established.  
