---
output: html_document
---

# (PART) RATIONALE AND OBJECTIVES  {-}

# The challenge of finding, accessing, and using data {#chapter01}

In the landscape of data sharing policies adopted by numerous national and international organizations, a common obstacle emerges for researchers and other data users. The challenge they face centers on the practicality of finding, accessing, and using data in an efficient manner. Navigating through a vast and ever-growing pool of data sources and types can be a complex, time-consuming endeavor. It involves identifying pertinent sources, acquiring and comprehending relevant datasets, and efficiently analyzing them. This challenge is marked by issues such as inadequate metadata, limitations of data discovery systems, and low visibility of valuable data reopsitories and cataloguing systems. The technical hurdles to data discoverability, accessibility, and usability must be addressed to enhance the effectiveness of data sharing policies and maximize the utility of collected data. In the upcoming sections, we will delve into these challenges.

## Finding data

Researchers identify and acquire data in various ways. Some rely on personal networks to find and obtain the data they need, which can lead to the use of "convenient" data that may not be the most relevant. Others locate datasets of interest in academic publications, which can be challenging as datasets are often not cited in a consistent or standardized manner. But many researchers search specialized data catalogs or use general search engines to locate relevant datasets or catalogs.

General search engines such as Google and Bing have remarkable capabilities in locating and ranking relevant resources available online, and in some cases, returning instant answers to users' queries. However, these search engines are designed to answer relatively simple queries and may not be able to find or recommend the most relevant data to help researchers answer complex research questions. Additionally, some relevant data may be hidden in locations such as article supplements, attachments to publications, or available as data services and not as datasets, making it challenging to locate them. Other datasets may be available in open data repositories but published with limited metadata, making them mostly invisible to web crawlers. Due to data being scattered across many sources and locations and published with metadata that is not optimized for search engines, users without prior knowledge of the existence and possible location of the data may be poorly served. Google's Dataset Search is one attempt to implement a better search engine for a catalog of datasets, but its performance is also hampered by the paucity of available metadata.

While general search engines are crucial in directing users to relevant catalogs and repositories, specialized online data catalogs and platforms maintained by national or international organizations, academic data centers, data archives, or data libraries are better suited for researchers seeking relevant data. These organizations provide critical data curation services. However, the search algorithms integrated into their data catalogs can sometimes provide unsatisfactory search results due to weaknesses in metadata associated with data resources and the lack of optimization of search indexes and algorithms. Administrators of these catalogs have a responsibility to ensure that their assets are visible in general search engines, and that the search engines and other discovery tools implemented in their catalogs provide an optimized user experience.

The few examples provided below illustrate some of the problems that researchers encounter when searching for data.[2] 

**Example 1: Searching for data on education and income inequality in Kenya using Google**

Suppose an analyst wants to study the correlation between education and inequality in Kenya. Such an analysis requires microdata from household surveys. The challenge here is to locate a certain type of data (microdata), covering not one but a combination of topics (education and income inequality). A Google search for "data on inequality and education in Kenya" returns useful links, but mostly to publications and blogs. Among the top 100 results, none provides a link to a relevant survey dataset.  

<br>
<center>
![image](https://user-images.githubusercontent.com/35276300/229517716-ec3e24d8-7303-4233-83e3-1cdf2f63c458.png)
</center>
<br>

A more specific query for "survey microdata on income inequality and education in Kenya" returns more relevant results, including a link to the *Kenya Integrated Household Budget Survey 2015-2016* from the microdata catalog maintained by the Kenya Bureau of Statistics. But the 49 results returned by Google do not include other existing relevant survey datasets that contain variables on education and on household income --such as the *kenya Integrated Household Budget Survey 2005-2006*-- or the other surveys that collected data on education and on proxies of household income such as household expenditure or assets ownership.

**Example 2: Searching for *child malnutrition* in the [US Open Data platform (data.gov)](https://catalog.data.gov)**

This second example illustrates the challenge of finding data based on a query that is not optimized to match the (unknown) metadata indexed in a catalog. The success of a search query depends largely on the user's ability to formulate a clear query, but what may seem clear to a human may not be seen that way by search algorithms. Many search algorithms rely on keyword search, which means they look for an exact match between keywords in a query and keywords in the index (or a stemmed or lemmatized version of the keywords). However, this approach has limitations as synonyms or related terms may not be recognized. A search for data on "child malnutrition" illustrates this. Child malnutrition is typically measured by the percentage of children stunted, wasted, and overweight. Queries for "child malnutrition", "children stunted", "children wasted", and "children overweight" in the U.S. Government’s open data platform (data.gov) return different results, with little overlap between the results of the four queries. 

<br>
<center>
![](./images/search_issue_data_gov1a.JPG){width=90%}
</center>
<br>

<br>
<center>
![](./images/search_issue_data_gov1b.JPG){width=90%}
</center>
<br>

<br>
<center>
![](./images/search_issue_data_gov1c.JPG){width=90%}
</center>
<br>

<br>
<center>
![](./images/search_issue_data_gov1d.JPG){width=90%}
</center>
<br>

Finding indicators appears to be challenging. Finding relevant microdata would be even more problematic. Unless the data curator has included "child malnutrition" as a keyword in the metadata, the search algorithm would have to understand that datasets containing variables *age in months*, *height*, and *weight* are relevant. Metadata augmentation, and the implementation of smarter search algorithms (with semantic capability) are the solutions to this problem.

**Example 3: Searching for *GDP per capita India 2020* in Google**

This third and last example illustrates the challenge of identifying the most relevant and accurate data. Search engine like Google and Bing are increasingly designed to return not just links, but **answers**. Advanced machine learning and natural language processing (NLP) solutions parse the queries and provide a direct answer when possible. ChatBoxes provide answers in conversation mode. Algorithms will make decisions on what data are most suitable. A search for *GDP per capita India 2021* on Google provides an immediate answer in the form of a graph by extracting information published by the World Bank (as of April 2nd, 2023):

<br>
<center>
![image](https://user-images.githubusercontent.com/35276300/229374995-ed83ca65-964d-464c-8668-0f390563bef4.png){width=90%}
</center>
<br>

The answer mentions "Sources include: World Bank". The World Bank is indeed probably the source from which the data used by Google are extracted. But the World Bank does not compile national accounts and the official producer of GDP estimates for India is the Ministry of Statistics (MOSPI). MOSPI's website only appears in the 7th page of results (with a link to a PDF document, not to MOSPI's website or data catalog), a page that few users will ever access. For many users, the source of the information may not matter; but for others, a link to the official source - where more metadata and related data may be found - could be more relevant.  

<br>
<center>
![](./images/gdp_india_2_2.JPG){width=90%}
</center>
<br>

The same query on chatGPT returns the following information.

<br>
<center>
![image](https://user-images.githubusercontent.com/35276300/229367133-ae5b1319-4682-46ef-8073-856f9e63149d.png){width=90%}
</center>
<br>

Both Google and chatGPT mention the WorldBank as the source. chatGPT provide results that differ from the information available in the World Bank website. And both make a choice on behalf of the user by providing a single indicator, while the World Bank database provides five different indicators that correspond to "GDP per capita".

<br>
<center>
![image](https://user-images.githubusercontent.com/35276300/229374548-6036a86f-d8c4-49bd-a916-73d7ad35ee79.png){width=60%}
</center>
<br>

**Example 4: Searching for data on a specific geographic areas**

Suppose a health official looks for data on measles vaccination in Oromia, a state of Ethiopia. Searching for "data on measles vaccination coverage in Oromia' returns 41 results. Searching for "data on measles vaccination coverage in the state of Oromia Ethiopia' returns 36 results. These results do not include the dataset "Ethiopia - Measles Vaccination Coverage" from WorldPop, which provides estimates of measles coverage in the form of raster data covering the entire territory of Ethiopia, at a very disaggregated level (areas of approximately 100m by 100m). This is in part due to sub-optimal search engine optimization of the website, but even if its content had been properly indexed by Google, the term "Oromia" would not have been detected as it does not appear in the description of the dataset. Listing all geographic areas covered by a geographic (or other) dataset would in many cases be very impractical, so better options need to be offered to make datasets discoverable based on the sub-national areas they cover.  

<br>
<center>
![image](https://user-images.githubusercontent.com/35276300/230107403-980cfb66-fa5f-4545-a5c9-2e9e4260a18b.png)
</center>
<br>

<br>
<center>
![image](https://user-images.githubusercontent.com/35276300/230108342-484d0c25-796f-4262-9487-5b45cf1402d8.png)
</center>
<br>

<br>
<center>
![image](https://user-images.githubusercontent.com/35276300/230109748-0dbd345d-e049-443a-a7b3-03d61339f788.png)
</center>
<br>


Finding data includes assessing data

Ideally, researchers should have easy access to both relevant datasets and the metadata required to evaluate the data's suitability for their specific purposes. Obtaining a dataset may be time-consuming and sometimes costly. Therefore, users should only invest resources and time in acquiring data that they know is of high quality and relevance.

Assessing a dataset's fitness for a specific purpose necessitates different metadata elements for varying data types and uses. Some metadata elements are straightforward, such as data type, temporal coverage, geographic coverage, scope and universe, and access policy. However, more detailed information may be required. For instance, a survey dataset (microdata) may only be relevant to a researcher if a specific modality of a specific variable has a sufficient number of respondents. If the sample size is minimal, the dataset would not allow for any valid statistical inference. Furthermore, comparability across sources is crucial to many users and uses, so the metadata should provide a detailed description of sampling, universe, variables, concepts, and methods relevant to the data type. A data user may also require information on the frequency of data updates (for time series or panel surveys, for example) and on previous uses of the dataset by the research community.

Even when data access is restricted, detailed metadata should be available openly and through a user-friendly interface.

## Accessing data

Accessing development data is a multifaceted challenge that involves legal, ethical, and practical considerations. To ensure that data access is legal, ethical and enables relevant and responsible use of the data, data providers and users must adhere to certain principles and practices:

- Data ownership and usage rights: Data providers must ensure that they have the legal rights to share the data and that they define clear usage rights for data users. Data users need to know how they can use the data, whether it's for research, commercial purposes, or other applications, and they must strictly comply with the terms of use.
- Data privacy and protection: Data access should comply with data privacy laws and ethical standards. Sensitive or personally identifiable information must be handled with care to protect individuals' privacy.
- Metadata provision: Data providers must offer comprehensive metadata that provides context and full understanding of the data. Metadata should include details about the data's provenance, including its history, transformations, and processing steps. Understanding how the data was created and modified is essential for accurate and responsible analysis. 
- Efficient data formats and modes of access: Data should be available in formats that are user-friendly and compatible with common data analysis tools. Common formats like CSV, JSON, or Excel can be practical choices. Data should be made accessible through various means, considering users' preferences and capacities. This might involve offering downloadable files, providing access through web-based tools, and supporting data streaming. APIs are crucial for enabling programmable access to data. They allow researchers to retrieve and manipulate data programmatically, integrating it into their research workflows and applications.
- Challenges specific to researchers in developing countries: Researchers in developing countries often face additional challenges in accessing data. These challenges include:
   - Lack of resources: Researchers in developing countries may not have the financial resources to purchase data or to access data that is stored in expensive cloud-based repositories.
   - Lack of infrastructure: Researchers in developing countries may not have access to the high-speed internet and computing resources that are needed to work with large datasets.
   - Lack of expertise: Researchers in developing countries may not have the expertise to work with complex data formats and to use data analysis tools.

## Using data

The challenge for data users is not only to discover data, but also to obtain all necessary information to fully understand the data and to use them responsibly and appropriately. A same indicator label, for example *unemployment rate (%)*, can mask significant differences by country, source, and time. The international recommendations for the definition and calculation of *unemployment rate* has changed over time, and not all countries use the same data collection instrument (labor force survey or other) to collect the underlying data. In on-line data dissemination platforms, detailed metadata should therefore always be associated and disseminated with the data. This must be a close association; the relevant metadata will ideally not be more than one click away from the data. This is particularly critical when a platform publishes data from multiple sources that are not fully harmonized.

:::quote
The scope and meaning of labour statistics in general are determined by their source and methodology, and this is certainly true for the unemployment rate. In order to interpret the data accurately, it is crucial to understand what the data convey and how they were collected and constructed, which implies having information on the relevant metadata. The design and characteristics of the data source (typically a labour force survey or similar household survey for the unemployment rate), especially in terms of definitions and concepts used, geographical and age coverage, and reference periods have great implications for the resulting data, making it crucial to take them into account when analysing the statistics. It is also essential to seek information on any methodological changes and breaks in series to assess their impact for trend analysis, and to keep in mind methodological differences across countries when conducting cross-country studies. (From [*Quick guide on interpreting the unemployment rate*](https://ilo.org/wcmsp5/groups/public/---dgreports/---stat/documents/publication/wcms_675155.pdf), International Labour Office – Geneva: ILO, 2019, ISBN : 978-92-2-133323-4 (web pdf)).
:::

When possible, reproducible or replicable scripts that made use of the data, and the analytical output of these scripts, should be published with the data. These scripts may be highly valuable to researchers who may want to expand the scope of previous data analysis or re-purpose part of the code, and to students who may learn from reading and replicating the work of experienced analysts. To foster the usability of data, we developed a specific metadata schema for the documentation of research projects and scripts.  


## A FAIR solution

To effectively address the information retrieval challenge, researchers should consider not only the content of the information but also the context within which it is created and the diverse range of potential users who may need it. A foundational element is being mindful of users and their potential interactions with the data and work. To improve search capabilities and increase the visibility of specialized data libraries, a combination of better data curation, search engines, and increased accessibility is necessary. Adhering to the FAIR principles (Findable, Accessible, Interoperable, and Reusable) is an effective approach to data management. (https://doi.org/10.1371/journal.pcbi.1008469)

It is essential to focus on the entire data curation process, from acquisition to dissemination, to optimize data analysis by streamlining the process of finding, assessing, accessing, and preparing data. This requires anticipating user needs and investing in the curation of data for reuse. To ensure data is **findable**, libraries should implement advanced search algorithms and filters, including full-text, advanced, semantic, and recommendation-based search options. Search engine optimization is also crucial for making catalogs more **accessible**. Additionally, multiple modes of data access should be available to improve accessibility, while data should be made **interoperable** to promote data sharing and reusability. Detailed metadata, including fitness for purpose assessments, should be displayed, alongside scripts and permanent availability options, such as a DOI, to promote **reuse**.

In chapter 2, we define the features of a modern catalog in more detail.

[2] The results shown are for a specific date, and are subject to variation over time.
